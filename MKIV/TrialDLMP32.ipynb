{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final version of the Phonk Beat (Maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        # Implement fallback to audioread if necessary\n",
    "        # For simplicity, this part is omitted\n",
    "        raise e\n",
    "\n",
    "def time_stretch_audio_to_match(audio, sr, target_length):\n",
    "    \"\"\"Time-stretch the audio to match the target length.\"\"\"\n",
    "    current_length = librosa.get_duration(y=audio, sr=sr)\n",
    "    stretch_factor = target_length / current_length\n",
    "    return librosa.effects.time_stretch(audio, rate=stretch_factor), sr\n",
    "\n",
    "def mix_and_sync_vocals_with_beat(vocals_filename, beat_filename, output_filename, beat_delay_seconds=0):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals, start_offset=beat_delay_seconds)\n",
    "\n",
    "    # Time-stretch vocals to match the beat's length\n",
    "    beat_length_seconds = librosa.get_duration(y=beat, sr=sr_beat)\n",
    "    vocals_stretched, _ = time_stretch_audio_to_match(vocals, sr_vocals, beat_length_seconds)\n",
    "\n",
    "    # Ensure both tracks are of the same length after stretching\n",
    "    max_length = max(len(vocals_stretched), len(beat))\n",
    "    if len(vocals_stretched) < max_length:\n",
    "        vocals_stretched = np.concatenate((vocals_stretched, np.zeros(max_length - len(vocals_stretched))))\n",
    "    if len(beat) < max_length:\n",
    "        beat = np.concatenate((beat, np.zeros(max_length - len(beat))))\n",
    "\n",
    "    # Mix the stretched vocals and the beat\n",
    "    mixed = vocals_stretched + beat\n",
    "    mixed = mixed / np.max(np.abs(mixed))\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = r\"latest_input.wav\"\n",
    "    beat_file = r\"beat_client.wav\"\n",
    "    output_file = r\"Phonk_Final_Synced2.wav\"\n",
    "\n",
    "    mix_and_sync_vocals_with_beat(vocals_file, beat_file, output_file, beat_delay_seconds=3.0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        # Ensure librosa is correctly installed and updated.\n",
    "        audio, sr = librosa.load(path=file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def time_stretch_audio_to_match(audio, sr, target_length):\n",
    "    current_length = librosa.get_duration(y=audio, sr=sr)\n",
    "    stretch_factor = target_length / current_length\n",
    "    return librosa.effects.time_stretch(audio, rate=stretch_factor), sr\n",
    "\n",
    "def align_tracks_dtw(track1, track2, sr):\n",
    "    distance, path = fastdtw(track1, track2, dist=euclidean)\n",
    "    # This example does not directly use the path for stretching but uses DTW distance as a guide.\n",
    "    # Implementing precise segment-wise stretching based on DTW path would require a more complex approach.\n",
    "    return path\n",
    "\n",
    "def mix_and_sync_vocals_with_beat(vocals_filename, beat_filename, output_filename, beat_delay_seconds=0):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals, start_offset=beat_delay_seconds)\n",
    "\n",
    "    # Calculate the number of samples to delay the beat by\n",
    "    beat_delay_samples = int(sr_vocals * beat_delay_seconds)\n",
    "\n",
    "    # Time-stretch vocals to match the beat's length, if necessary\n",
    "    # This step is based on your previous requirement; adjust as needed\n",
    "\n",
    "    # Prepare the beat: pad the beginning with zeros based on the delay, then trim or extend to match vocals length\n",
    "    beat_padded = np.zeros_like(vocals)\n",
    "    beat_length = min(len(beat), len(beat_padded) - beat_delay_samples)  # Ensure beat does not exceed vocal length after delay\n",
    "    beat_padded[beat_delay_samples:beat_delay_samples+beat_length] = beat[:beat_length]\n",
    "\n",
    "    # Mix the vocals and the adjusted beat\n",
    "    mixed = vocals + beat_padded\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = r\"latest_input.wav\"\n",
    "    beat_file = r\"beat_client.wav\"\n",
    "    output_file = r\"Phonk_Final_Synced2.wav\"\n",
    "\n",
    "    mix_and_sync_vocals_with_beat(vocals_file, beat_file, output_file, beat_delay_seconds=0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        # Ensure librosa is correctly installed and updated.\n",
    "        audio, sr = librosa.load(path=file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def time_stretch_audio_to_match(audio, sr, target_length):\n",
    "    current_length = librosa.get_duration(y=audio, sr=sr)\n",
    "    stretch_factor = target_length / current_length\n",
    "    return librosa.effects.time_stretch(audio, rate=stretch_factor), sr\n",
    "\n",
    "def align_tracks_dtw(track1, track2, sr):\n",
    "    distance, path = fastdtw(track1, track2, dist=euclidean)\n",
    "    # This example does not directly use the path for stretching but uses DTW distance as a guide.\n",
    "    # Implementing precise segment-wise stretching based on DTW path would require a more complex approach.\n",
    "    return path\n",
    "\n",
    "def mix_and_sync_vocals_with_beat(vocals_filename, beat_filename, output_filename, beat_delay_seconds=0, vocal_stretch_factor=0.83):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals, start_offset=beat_delay_seconds)\n",
    "\n",
    "    # Stretch the vocals by the specified factor\n",
    "    if vocal_stretch_factor != 1.0:\n",
    "        vocals = librosa.effects.time_stretch(vocals, rate=vocal_stretch_factor)\n",
    "\n",
    "    # Calculate the number of samples to delay the beat by\n",
    "    beat_delay_samples = int(sr_vocals * beat_delay_seconds)\n",
    "\n",
    "    # Prepare the beat: pad the beginning with zeros based on the delay, then trim or extend to match vocals length\n",
    "    beat_padded = np.zeros_like(vocals)\n",
    "    beat_length = min(len(beat), len(beat_padded) - beat_delay_samples)  # Ensure beat does not exceed vocal length after delay\n",
    "    beat_padded[beat_delay_samples:beat_delay_samples+beat_length] = beat[:beat_length]\n",
    "\n",
    "    # Mix the vocals and the adjusted beat\n",
    "    mixed = vocals + beat_padded\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = r\"latest_input.wav\"\n",
    "    beat_file = r\"beat_client.wav\"\n",
    "    output_file = r\"Phonk_Final_Synced3.wav\"\n",
    "\n",
    "    mix_and_sync_vocals_with_beat(vocals_file, beat_file, output_file, beat_delay_seconds=0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        # Ensure librosa is correctly installed and updated.\n",
    "        audio, sr = librosa.load(path=file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def time_stretch_audio_to_match(audio, sr, target_length):\n",
    "    current_length = librosa.get_duration(y=audio, sr=sr)\n",
    "    stretch_factor = target_length / current_length\n",
    "    return librosa.effects.time_stretch(audio, rate=stretch_factor), sr\n",
    "\n",
    "def align_tracks_dtw(track1, track2, sr):\n",
    "    distance, path = fastdtw(track1, track2, dist=euclidean)\n",
    "    # This example does not directly use the path for stretching but uses DTW distance as a guide.\n",
    "    # Implementing precise segment-wise stretching based on DTW path would require a more complex approach.\n",
    "    return path\n",
    "\n",
    "def mix_and_sync_vocals_with_beat(vocals_filename, beat_filename, output_filename, beat_delay_seconds=0, vocal_stretch_factor=0.83):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals, start_offset=beat_delay_seconds)\n",
    "\n",
    "    # Stretch the vocals by the specified factor\n",
    "    if vocal_stretch_factor != 1.0:\n",
    "        vocals = librosa.effects.time_stretch(vocals, rate=vocal_stretch_factor)\n",
    "\n",
    "    # Calculate the number of samples to delay the beat by\n",
    "    beat_delay_samples = int(sr_vocals * beat_delay_seconds)\n",
    "\n",
    "    # Prepare the beat: pad the beginning with zeros based on the delay, then trim or extend to match vocals length\n",
    "    beat_padded = np.zeros_like(vocals)\n",
    "    beat_length = min(len(beat), len(beat_padded) - beat_delay_samples)  # Ensure beat does not exceed vocal length after delay\n",
    "    beat_padded[beat_delay_samples:beat_delay_samples+beat_length] = beat[:beat_length]\n",
    "\n",
    "    # Mix the vocals and the adjusted beat\n",
    "    mixed = vocals + beat_padded\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = r\"latest_input.wav\"\n",
    "    beat_file = r\"Beat.wav\"\n",
    "    output_file = r\"Phonk_Final_Synced4.wav\"\n",
    "\n",
    "    mix_and_sync_vocals_with_beat(vocals_file, beat_file, output_file, beat_delay_seconds=0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        raise e\n",
    "\n",
    "def mix_and_sync_vocals_with_beat(vocals_filename, beat_filename, output_filename, beat_delay_seconds=0, vocal_stretch_factor=0.8):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals, start_offset=beat_delay_seconds)\n",
    "\n",
    "    # Stretch the vocals using pyrubberband\n",
    "    if vocal_stretch_factor != 1.0:\n",
    "        vocals = pyrb.time_stretch(vocals, sr_vocals, vocal_stretch_factor)\n",
    "\n",
    "    # Calculate the number of samples to delay the beat by\n",
    "    beat_delay_samples = int(sr_vocals * beat_delay_seconds)\n",
    "\n",
    "    # Prepare the beat: pad the beginning with zeros based on the delay, then trim or extend to match vocals length\n",
    "    beat_padded = np.zeros_like(vocals)\n",
    "    beat_length = min(len(beat), len(beat_padded) - beat_delay_samples)  # Ensure beat does not exceed vocal length after delay\n",
    "    beat_padded[beat_delay_samples:beat_delay_samples+beat_length] = beat[:beat_length]\n",
    "\n",
    "    # Mix the vocals and the adjusted beat\n",
    "    mixed = vocals + beat_padded\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"latest_input.wav\"\n",
    "    beat_file = \"beat_client.wav\"\n",
    "    output_file = \"Phonk_Final_Synced2_1.wav\"\n",
    "    mix_and_sync_vocals_with_beat(vocals_file, beat_file, output_file, beat_delay_seconds=0, vocal_stretch_factor=0.8)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None, start_offset=0):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr, offset=start_offset)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}\")\n",
    "        raise e\n",
    "\n",
    "def stretch_audio(file_path, output_filename, stretch_factor=0.8):\n",
    "    audio, sr = load_audio_with_fallback(file_path, sr=None)\n",
    "\n",
    "    # Stretch the audio using pyrubberband\n",
    "    if stretch_factor != 1.0:\n",
    "        audio_stretched = pyrb.time_stretch(audio, sr, stretch_factor)\n",
    "    else:\n",
    "        audio_stretched = audio\n",
    "\n",
    "    sf.write(output_filename, audio_stretched, sr)\n",
    "\n",
    "def main():\n",
    "    input_file = \"latest_input.wav\"\n",
    "    output_file = \"Audio_002_Without_Beat.wav\"\n",
    "    stretch_factor = 0.8  # Adjust the stretch factor as needed\n",
    "    stretch_audio(input_file, output_file, stretch_factor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mr. Krystof Wants to sync the beat without having any delay in the audio that too without slowing down the source audio so we decided to provide that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "def load_audio(file_path, sr=None):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def stretch_audio(audio, sr, stretch_factor=1.0):\n",
    "    if stretch_factor != 1.0:\n",
    "        return pyrb.time_stretch(audio, sr, stretch_factor)\n",
    "    return audio\n",
    "\n",
    "def synchronize_beat(vocals_audio, beat_audio, sr):\n",
    "    # Assuming no need to stretch the beat, just align it to start with vocals\n",
    "    vocals_length = len(vocals_audio)\n",
    "    beat_length = len(beat_audio)\n",
    "    \n",
    "    if beat_length < vocals_length:\n",
    "        # If beat is shorter than vocals, loop the beat\n",
    "        loop_count = int(np.ceil(vocals_length / beat_length))\n",
    "        beat_audio = np.tile(beat_audio, loop_count)[:vocals_length]\n",
    "    else:\n",
    "        # If beat is longer, trim it to match vocals length\n",
    "        beat_audio = beat_audio[:vocals_length]\n",
    "\n",
    "    return beat_audio\n",
    "\n",
    "def process_audio(vocals_path, beat_path, output_path, stretch_factor=1.0):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    if vocals is None:\n",
    "        return\n",
    "    vocals = stretch_audio(vocals, sr, stretch_factor)\n",
    "    \n",
    "    beat, _ = load_audio(beat_path, sr)\n",
    "    if beat is None:\n",
    "        return\n",
    "    \n",
    "    beat_synced = synchronize_beat(vocals, beat, sr)\n",
    "    \n",
    "    # Mix vocals and beat\n",
    "    mixed = vocals + beat_synced\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "    \n",
    "    try:\n",
    "        sf.write(output_path, mixed, sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write output file: {e}\")\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"latest_input.wav\"\n",
    "    beat_file = \"beat_client.wav\"\n",
    "    output_file = \"Final_Output_Synced_Beat_S.wav\"\n",
    "    stretch_factor = 1.0  # Change if needed\n",
    "    process_audio(vocals_file, beat_file, output_file, stretch_factor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One more change was proposed, it needs to be done in such a way that the time between the words decreases but the speed of the file remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW - NOT WORKING MAYBE\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    return audio, sr\n",
    "\n",
    "def reduce_silences(audio, sr, top_db=10, silence_reduction_factor=0.1):\n",
    "    # Detect non-silent intervals\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "\n",
    "    processed_audio_segments = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end in non_silent_intervals:\n",
    "        # Append silence reduced by the specified factor\n",
    "        if start > last_end:\n",
    "            silence_duration = start - last_end\n",
    "            reduced_silence_duration = int(silence_duration * silence_reduction_factor)\n",
    "            silence_segment = np.zeros(reduced_silence_duration)\n",
    "            processed_audio_segments.append(silence_segment)\n",
    "\n",
    "        # Append the current non-silent audio segment\n",
    "        processed_audio_segments.append(audio[last_end:end])\n",
    "        last_end = end\n",
    "\n",
    "    # Concatenate all segments\n",
    "    processed_audio = np.concatenate(processed_audio_segments)\n",
    "\n",
    "    return processed_audio\n",
    "\n",
    "def process_audio(vocals_path, output_path, silence_reduction_factor=0.1):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    vocals_reduced_silence = reduce_silences(vocals, sr, silence_reduction_factor=silence_reduction_factor)\n",
    "    sf.write(output_path, vocals_reduced_silence, sr)\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"Final_Output_Synced_Beat.wav\"\n",
    "    output_file = \"reduced_silence_output_3.wav\"\n",
    "    process_audio(vocals_file, output_file, silence_reduction_factor=0.1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD - SEEMS TO WORK WAITING FOR CLIENT APPROVAL -- Approved but last change needed\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    return audio, sr\n",
    "\n",
    "def reduce_silences(audio, sr, top_db=25, reduce_by_factor=0.3):\n",
    "    # Detect non-silent intervals\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "\n",
    "    # Initialize an empty list to hold processed (shortened silence) audio\n",
    "    processed_audio = []\n",
    "\n",
    "    # Process each non-silent interval\n",
    "    for i, (start, end) in enumerate(non_silent_intervals):\n",
    "        # Append the current non-silent audio segment to the processed_audio list\n",
    "        processed_audio.append(audio[start:end])\n",
    "\n",
    "        if i < len(non_silent_intervals) - 1:\n",
    "            # Calculate the duration of the next silence\n",
    "            next_start = non_silent_intervals[i + 1][0]\n",
    "            silence_duration = next_start - end\n",
    "\n",
    "            # Reduce the silence duration by the specified factor\n",
    "            reduced_silence_duration = int(silence_duration * reduce_by_factor)\n",
    "\n",
    "            # Create a silence segment of the reduced duration\n",
    "            silence_segment = np.zeros(reduced_silence_duration)\n",
    "\n",
    "            # Append the reduced silence segment to the processed_audio list\n",
    "            processed_audio.append(silence_segment)\n",
    "\n",
    "    # Concatenate all processed audio segments back together\n",
    "    processed_audio = np.concatenate(processed_audio)\n",
    "\n",
    "    return processed_audio\n",
    "\n",
    "def process_audio(vocals_path, output_path, reduce_by_factor=0.3):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    vocals_reduced_silence = reduce_silences(vocals, sr, reduce_by_factor=reduce_by_factor)\n",
    "    sf.write(output_path, vocals_reduced_silence, sr)\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"Final_Output_Synced_Beat.wav\"\n",
    "    output_file = \"reduced_silence_output_F.wav\"\n",
    "    process_audio(vocals_file, output_file, reduce_by_factor=0.3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15/03/24 - Last Changes Oncoming\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    return audio, sr\n",
    "\n",
    "def reduce_silences(audio, sr, top_db=22, reduce_by_factor=0.0011):\n",
    "    # Detect non-silent intervals\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "\n",
    "    # Initialize an empty list to hold processed (shortened silence) audio\n",
    "    processed_audio = []\n",
    "\n",
    "    # Process each non-silent interval\n",
    "    for i, (start, end) in enumerate(non_silent_intervals):\n",
    "        # Append the current non-silent audio segment to the processed_audio list\n",
    "        processed_audio.append(audio[start:end])\n",
    "\n",
    "        if i < len(non_silent_intervals) - 1:\n",
    "            # Calculate the duration of the next silence\n",
    "            next_start = non_silent_intervals[i + 1][0]\n",
    "            silence_duration = next_start - end\n",
    "\n",
    "            # Reduce the silence duration by the specified factor\n",
    "            reduced_silence_duration = int(silence_duration * reduce_by_factor)\n",
    "\n",
    "            # Create a silence segment of the reduced duration\n",
    "            silence_segment = np.zeros(reduced_silence_duration)\n",
    "\n",
    "            # Append the reduced silence segment to the processed_audio list\n",
    "            processed_audio.append(silence_segment)\n",
    "\n",
    "    # Concatenate all processed audio segments back together\n",
    "    processed_audio = np.concatenate(processed_audio)\n",
    "\n",
    "    return processed_audio\n",
    "\n",
    "def process_audio(vocals_path, output_path, reduce_by_factor=0.0011):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    vocals_reduced_silence = reduce_silences(vocals, sr, reduce_by_factor=reduce_by_factor)\n",
    "    sf.write(output_path, vocals_reduced_silence, sr)\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"Final_Output_Synced_Beat.wav\"\n",
    "    output_file = \"reduced_silence_output_F2.wav\"\n",
    "    process_audio(vocals_file, output_file, reduce_by_factor=0.0011)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While researching a thing came to my mind there are chances that the delay is not reduced because also the beat is there in the audio what if we process the audio standalone first and then insert the beat after the audio quality turns out to be perfect.\n",
    "\n",
    "##### So below is the trial of the above mentioned experiment\n",
    "\n",
    "\n",
    "# Expermimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seems to have worked as the client said - \"This is Perfect!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    return audio, sr\n",
    "\n",
    "def reduce_silences(audio, sr, top_db=22, max_reduction_factor=0.011):\n",
    "    # Detect non-silent intervals\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "    processed_audio = []\n",
    "\n",
    "    for i, (start, end) in enumerate(non_silent_intervals):\n",
    "        processed_audio.append(audio[start:end])\n",
    "        if i < len(non_silent_intervals) - 1:\n",
    "            next_start = non_silent_intervals[i + 1][0]\n",
    "            silence_duration = next_start - end\n",
    "            reduction_factor = max(0.01, max_reduction_factor * (silence_duration / sr))\n",
    "            reduced_silence_duration = int(silence_duration * reduction_factor)\n",
    "            silence_segment = np.zeros(reduced_silence_duration)\n",
    "            processed_audio.append(silence_segment)\n",
    "\n",
    "    processed_audio = np.concatenate(processed_audio)\n",
    "    return processed_audio\n",
    "\n",
    "def speed_up_audio(audio, sr, speed_factor=0.6):\n",
    "    # Speed up the audio without changing the pitch\n",
    "    audio_fast = librosa.effects.time_stretch(audio, rate=1/speed_factor)\n",
    "    return audio_fast\n",
    "\n",
    "def process_audio(vocals_path, output_path, max_reduction_factor=0.011, speed_factor=0.6):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    vocals_reduced_silence = reduce_silences(vocals, sr, max_reduction_factor=max_reduction_factor)\n",
    "    vocals_speed_up = speed_up_audio(vocals_reduced_silence, sr, speed_factor=speed_factor)\n",
    "    sf.write(output_path, vocals_speed_up, sr)\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"latest_input.wav\"\n",
    "    output_file = \"reduced_delay_speed_up_output.wav\"\n",
    "    process_audio(vocals_file, output_file, max_reduction_factor=0.011, speed_factor=0.6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will now be adding the beat and merging it with the audio - and all this while syncing it perfectly with the beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "def load_audio(file_path, sr=None):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def stretch_audio(audio, sr, stretch_factor=1.0):\n",
    "    if stretch_factor != 1.0:\n",
    "        return pyrb.time_stretch(audio, sr, stretch_factor)\n",
    "    return audio\n",
    "\n",
    "def synchronize_beat(vocals_audio, beat_audio, sr):\n",
    "    # Assuming no need to stretch the beat, just align it to start with vocals\n",
    "    vocals_length = len(vocals_audio)\n",
    "    beat_length = len(beat_audio)\n",
    "    \n",
    "    if beat_length < vocals_length:\n",
    "        # If beat is shorter than vocals, loop the beat\n",
    "        loop_count = int(np.ceil(vocals_length / beat_length))\n",
    "        beat_audio = np.tile(beat_audio, loop_count)[:vocals_length]\n",
    "    else:\n",
    "        # If beat is longer, trim it to match vocals length\n",
    "        beat_audio = beat_audio[:vocals_length]\n",
    "\n",
    "    return beat_audio\n",
    "\n",
    "def process_audio(vocals_path, beat_path, output_path, stretch_factor=1.0):\n",
    "    vocals, sr = load_audio(vocals_path)\n",
    "    if vocals is None:\n",
    "        return\n",
    "    vocals = stretch_audio(vocals, sr, stretch_factor)\n",
    "    \n",
    "    beat, _ = load_audio(beat_path, sr)\n",
    "    if beat is None:\n",
    "        return\n",
    "    \n",
    "    beat_synced = synchronize_beat(vocals, beat, sr)\n",
    "    \n",
    "    # Mix vocals and beat\n",
    "    mixed = vocals + beat_synced\n",
    "    mixed = mixed / np.max(np.abs(mixed))  # Normalize to prevent clipping\n",
    "    \n",
    "    try:\n",
    "        sf.write(output_path, mixed, sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write output file: {e}\")\n",
    "\n",
    "def main():\n",
    "    vocals_file = \"reduced_delay_speed_up_output.wav\"\n",
    "    beat_file = \"beat_client.wav\"\n",
    "    output_file = \"Audio_003_1503.wav\"\n",
    "    stretch_factor = 0.95  # Change if needed\n",
    "    process_audio(vocals_file, beat_file, output_file, stretch_factor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poojan latest\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import audioread\n",
    "\n",
    "def simple_delay_reverb(audio, sr, delay_ms=300, decay=0, repeats=2):\n",
    "    delay_samples = int(sr * delay_ms / 1000)\n",
    "    output = np.copy(audio)\n",
    "    for _ in range(repeats):\n",
    "        delayed = np.zeros_like(output)\n",
    "        delayed[delay_samples:] = output[:-delay_samples]\n",
    "        output += delayed * decay\n",
    "    output = output / np.max(np.abs(output))\n",
    "    return output\n",
    "\n",
    "def load_audio_with_fallback(file_path, sr=None):\n",
    "    try:\n",
    "        return librosa.load(file_path, sr=sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load with librosa due to: {e}. Falling back to audioread.\")\n",
    "        with audioread.audio_open(file_path) as f:\n",
    "            data = np.hstack([np.frombuffer(chunk, np.int16) for chunk in f])\n",
    "            if sr is not None:\n",
    "                data = librosa.resample(data.astype(float), f.samplerate, sr)\n",
    "            return data, sr\n",
    "\n",
    "def modify_vocals(vocals_filename, beat_filename, output_filename, volume_gain=2.0, beat_start_time=0.0, pitch_shift_semitones=0):\n",
    "    vocals, sr_vocals = load_audio_with_fallback(vocals_filename, sr=None)\n",
    "    beat, sr_beat = load_audio_with_fallback(beat_filename, sr=sr_vocals)\n",
    "\n",
    "    if pitch_shift_semitones != 0:\n",
    "        vocals = librosa.effects.pitch_shift(vocals, sr_vocals, pitch_shift_semitones)\n",
    "\n",
    "    vocals = simple_delay_reverb(vocals, sr_vocals)\n",
    "\n",
    "    start_sample = int(beat_start_time * sr_beat)\n",
    "    if start_sample < len(beat):\n",
    "        beat = beat[start_sample:]\n",
    "    else:\n",
    "        raise ValueError(\"Beat start time exceeds the length of the beat track.\")\n",
    "\n",
    "    vocals = vocals * volume_gain\n",
    "\n",
    "    min_length = min(len(vocals), len(beat))\n",
    "    vocals = vocals[:min_length]\n",
    "    beat = beat[:min_length]\n",
    "\n",
    "    mixed = vocals + beat\n",
    "    mixed = mixed / np.max(np.abs(mixed))\n",
    "\n",
    "    sf.write(output_filename, mixed, sr_vocals)\n",
    "\n",
    "def main():\n",
    "    vocals_file = r\"reduced_delay_speed_up_output.wav\"\n",
    "    beat_file = r\"beat_client.wav\"\n",
    "    output_file = r\"Trial_P_O_3.wav\"\n",
    "\n",
    "    modify_vocals(vocals_file, beat_file, output_file, volume_gain=1.0, beat_start_time=1.955555, pitch_shift_semitones=0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
